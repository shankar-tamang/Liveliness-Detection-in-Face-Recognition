{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xHrlEg0PaBLP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50V2  # Using ResNet50V2\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZ9_oMEtawAS",
        "outputId": "3dcf616b-9cea-4d84-f714-574b9552a7a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94668760/94668760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#  1. Define the Pre-trained ResNet50V2 Model\n",
        "base_model = ResNet50V2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "t9O0SBffAmDY"
      },
      "outputs": [],
      "source": [
        "# 2. Add New Layers on Top of VGG16\n",
        "# 2. Add New Layers on Top of ResNet50V2\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "\n",
        "predictions = Dense(2, activation='softmax')(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dH2DM02WCubz"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 3. Create the Model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dW6d27qSCdA7"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=[\n",
        "        'accuracy',              # Basic accuracy metric\n",
        "    #     tf.keras.metrics.Precision(name='precision'),  # Precision metric\n",
        "    #     tf.keras.metrics.Recall(name='recall'),        # Recall metric\n",
        "    #     tf.keras.metrics.AUC(name='auc')               # AUC (Area Under the ROC Curve)\n",
        "     ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QRmoJppawWO",
        "outputId": "d4422587-eb44-4e04-afe6-6adf075727af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 593 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# 3. Data Augmentation and Loading\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "datagen_no_aug = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "all_images = datagen_no_aug.flow_from_directory(\n",
        "    r'dataset',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=663,  # Load all images at once (adjust if needed)\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ii4pFs0Cawi4"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# 4. Split the Dataset\n",
        "X_all, y_all = next(all_images)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
        "\n",
        "# 5. Create Data Generators for Each Set\n",
        "training_set = train_datagen.flow(X_train, y_train, batch_size=32)\n",
        "validation_set = datagen_no_aug.flow(X_val, y_val, batch_size=32)\n",
        "test_set = datagen_no_aug.flow(X_test, y_test, batch_size=32, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCf6WR7TawtL",
        "outputId": "7142bc77-db94-4566-eee8-459d878d5fce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Manjil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 5s/step - accuracy: 0.4941 - loss: 7.8309 - val_accuracy: 0.3782 - val_loss: 0.9876\n",
            "Epoch 2/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3s/step - accuracy: 0.4622 - loss: 1.2019 - val_accuracy: 0.8487 - val_loss: 0.5359\n",
            "Epoch 3/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3s/step - accuracy: 0.7348 - loss: 0.5513 - val_accuracy: 0.6639 - val_loss: 0.5848\n",
            "Epoch 4/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 4s/step - accuracy: 0.7272 - loss: 0.5523 - val_accuracy: 0.6807 - val_loss: 0.5023\n",
            "Epoch 5/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3s/step - accuracy: 0.7561 - loss: 0.5115 - val_accuracy: 0.8824 - val_loss: 0.4235\n",
            "Epoch 6/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3s/step - accuracy: 0.8423 - loss: 0.4156 - val_accuracy: 0.9244 - val_loss: 0.3638\n",
            "Epoch 7/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - accuracy: 0.7963 - loss: 0.4497 - val_accuracy: 0.8655 - val_loss: 0.3423\n",
            "Epoch 8/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 3s/step - accuracy: 0.8606 - loss: 0.3825 - val_accuracy: 0.9076 - val_loss: 0.3242\n",
            "Epoch 9/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 3s/step - accuracy: 0.8607 - loss: 0.3388 - val_accuracy: 0.8151 - val_loss: 0.3907\n",
            "Epoch 10/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 3s/step - accuracy: 0.8218 - loss: 0.3665 - val_accuracy: 0.8319 - val_loss: 0.3890\n",
            "Epoch 11/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3s/step - accuracy: 0.8139 - loss: 0.3871 - val_accuracy: 0.9244 - val_loss: 0.2678\n",
            "Epoch 12/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - accuracy: 0.8882 - loss: 0.2965 - val_accuracy: 0.7731 - val_loss: 0.3734\n",
            "Epoch 13/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3s/step - accuracy: 0.8425 - loss: 0.3546 - val_accuracy: 0.9412 - val_loss: 0.2454\n",
            "Epoch 14/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 3s/step - accuracy: 0.8968 - loss: 0.2605 - val_accuracy: 0.8992 - val_loss: 0.2728\n",
            "Epoch 15/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3s/step - accuracy: 0.8831 - loss: 0.2488 - val_accuracy: 0.9244 - val_loss: 0.2217\n",
            "Epoch 16/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.9221 - loss: 0.2392 - val_accuracy: 0.9160 - val_loss: 0.2173\n",
            "Epoch 17/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - accuracy: 0.9270 - loss: 0.2106 - val_accuracy: 0.9244 - val_loss: 0.2208\n",
            "Epoch 18/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - accuracy: 0.9228 - loss: 0.2356 - val_accuracy: 0.8571 - val_loss: 0.3357\n",
            "Epoch 19/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3s/step - accuracy: 0.9043 - loss: 0.2915 - val_accuracy: 0.7983 - val_loss: 0.3994\n",
            "Epoch 20/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1569s\u001b[0m 142s/step - accuracy: 0.7884 - loss: 0.4460 - val_accuracy: 0.8067 - val_loss: 0.3888\n",
            "Epoch 21/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 5s/step - accuracy: 0.9013 - loss: 0.2549 - val_accuracy: 0.9160 - val_loss: 0.1944\n",
            "Epoch 22/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 4s/step - accuracy: 0.8879 - loss: 0.2736 - val_accuracy: 0.9328 - val_loss: 0.2063\n",
            "Epoch 23/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3s/step - accuracy: 0.9146 - loss: 0.2082 - val_accuracy: 0.9412 - val_loss: 0.1695\n",
            "Epoch 24/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 4s/step - accuracy: 0.9455 - loss: 0.1841 - val_accuracy: 0.9328 - val_loss: 0.1765\n",
            "Epoch 25/25\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 4s/step - accuracy: 0.9370 - loss: 0.1791 - val_accuracy: 0.9328 - val_loss: 0.1704\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 6. Train the Model\n",
        "history = model.fit(\n",
        "    training_set,\n",
        "    epochs=25,  # Adjust the number of epochs as needed\n",
        "    validation_data=validation_set\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "MvttsSPMaw3E",
        "outputId": "b79df1c0-7dc3-4fd4-fa0e-a5f57988f78d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# 7. Save the Trained Model\n",
        "\n",
        "\n",
        "# Assume you have a trained model named `model`\n",
        "model.save('liveliness_detection_model_resnet.h5')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkOgBsFRZjXd",
        "outputId": "01379995-916f-49d2-da96-5673b4a81eae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9179 - loss: 0.2183\n",
            "Test Loss: 0.20079153776168823\n",
            "Test Accuracy: 0.9327731132507324\n"
          ]
        }
      ],
      "source": [
        "\n",
        "loss, accuracy = model.evaluate(test_set)   # Use the test_set generator directly\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
