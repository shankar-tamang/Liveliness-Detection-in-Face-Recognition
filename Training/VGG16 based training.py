# -*- coding: utf-8 -*-
"""liveliness_detection (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1N5zfUp-J7K6dt8IDgia-e0ca_3ioQDK_
"""

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
from tensorflow.keras.applications import VGG16
from tensorflow.keras.layers import Flatten, Dense
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split

# 1. Define the Pre-trained VGG16 Model
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
for layer in base_model.layers:
    layer.trainable = False

x = Flatten()(base_model.output)
x = Dense(1024, activation='relu')(x)
predictions = Dense(2, activation='softmax')(x)
model = Model(inputs=base_model.input, outputs=predictions)

# 2. Compile the Model
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# 3. Data Augmentation and Loading
train_datagen = ImageDataGenerator(
    rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)

datagen_no_aug = ImageDataGenerator(rescale=1./255)

all_images = datagen_no_aug.flow_from_directory(
    '/content/drive/My Drive/liveliness_dataset',
    target_size=(224, 224),
    batch_size=663,  # Load all images at once (adjust if needed)
    class_mode='binary',
    shuffle=False
)

# 4. Split the Dataset
X_all, y_all = next(all_images)
X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)

# 5. Create Data Generators for Each Set
training_set = train_datagen.flow(X_train, y_train, batch_size=32)
validation_set = datagen_no_aug.flow(X_val, y_val, batch_size=32)
test_set = datagen_no_aug.flow(X_test, y_test, batch_size=32, shuffle=False)

# 6. Train the Model
history = model.fit(
    training_set,
    epochs=10,  # Adjust the number of epochs as needed
    validation_data=validation_set
)

# 7. Save the Trained Model
from google.colab import files

# Save the model to the Colab filesystem
model.save('my_model.h5')

# Download the model to your local machine
files.download('my_model.h5')


# model.save('liveliness_detection_model.h5')

# Specify the path in Google Drive where you want to save the model
model_path = '/content/drive/My Drive/my_model.h5'
model.save(model_path)

"""# New section"""

# 3. Evaluate the Model
loss, accuracy = model.evaluate(test_set)
print("Test Loss:", loss)
print("Test Accuracy:", accuracy)

